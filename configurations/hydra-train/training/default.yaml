# @package _group_

# reproducibility
reprod:
  seed: 12

# optimization
trainer:
  gradient_acc_steps: 4
  gradient_clip_value: 10.0
  max_steps: 100000
  val_check_interval: 1000
  patience: 5
  optim:
    _target_: "src.optim.factories.TorchFactory"
    optimizer:
      _target_: torch.optim.Adam
      lr: 1e-5
  checkpoint:
    filename: '{val_loss:.4f}'
    monitor: '-val_loss'
    save_top_k: 5
    save_last: true

# logger
logger:
  _target_: 'pytorch_lightning.loggers.wandb.WandbLogger'
  name: ${exp_name}
  project: ${project_name}

